{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mArray{T}(::Type{T}, m::Int, n::Int) is deprecated, use Array{T}(m, n) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mArray\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Type{Float64}, ::Int64, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mtraindata\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\MNIST\\src\\MNIST.jl:88\u001b[22m\u001b[22m\n",
      " [4] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [5] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\IJulia\\src\\execute_request.jl:160\u001b[22m\u001b[22m\n",
      " [6] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m(::IJulia.##11#14)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[1], in expression starting on line 2\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mArray{T}(::Type{T}, m::Int) is deprecated, use Array{T}(m) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mArray\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Type{Float64}, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mtraindata\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\MNIST\\src\\MNIST.jl:89\u001b[22m\u001b[22m\n",
      " [4] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [5] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\IJulia\\src\\execute_request.jl:160\u001b[22m\u001b[22m\n",
      " [6] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m(::IJulia.##11#14)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[1], in expression starting on line 2\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mArray{T}(::Type{T}, m::Int, n::Int) is deprecated, use Array{T}(m, n) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mArray\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Type{Float64}, ::Int64, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mtestdata\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\MNIST\\src\\MNIST.jl:99\u001b[22m\u001b[22m\n",
      " [4] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [5] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\IJulia\\src\\execute_request.jl:160\u001b[22m\u001b[22m\n",
      " [6] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m(::IJulia.##11#14)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[1], in expression starting on line 3\n",
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mArray{T}(::Type{T}, m::Int) is deprecated, use Array{T}(m) instead.\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1mArray\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Type{Float64}, ::Int64\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\deprecated.jl:57\u001b[22m\u001b[22m\n",
      " [3] \u001b[1mtestdata\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\MNIST\\src\\MNIST.jl:100\u001b[22m\u001b[22m\n",
      " [4] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\loading.jl:515\u001b[22m\u001b[22m\n",
      " [5] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\IJulia\\src\\execute_request.jl:160\u001b[22m\u001b[22m\n",
      " [6] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1mC:\\Users\\User\\AppData\\Local\\JuliaPro-0.6.0.1\\pkgs-0.6.0.1\\v0.6\\IJulia\\src\\eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [7] \u001b[1m(::IJulia.##11#14)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m.\\task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[1], in expression starting on line 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10000-element Array{Int64,1}:\n",
       " 7\n",
       " 2\n",
       " 1\n",
       " 0\n",
       " 4\n",
       " 1\n",
       " 4\n",
       " 9\n",
       " 5\n",
       " 9\n",
       " 0\n",
       " 6\n",
       " 9\n",
       " ⋮\n",
       " 5\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9\n",
       " 0\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MNIST\n",
    "trainX, trainY = traindata()\n",
    "testX, testY = testdata()\n",
    "trainY=Int.(trainY)\n",
    "testY=Int.(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type NeuralNetwork\n",
    "    numOfLayers::Int\n",
    "    sizes::Array{Int,1}\n",
    "    biases::Array{Array{Float64,1},1}\n",
    "    weights::Array{Array{Float64,2},1}\n",
    "    function NeuralNetwork(s)\n",
    "        numOfLayers=length(s)\n",
    "        sizes=s\n",
    "        biases=[rand(y) for y in s[2:end]]\n",
    "        weights=[rand(y,x) for (x,y) in zip(s[1:end-1],s[2:end])]\n",
    "        new(numOfLayers,sizes,biases,weights)\n",
    "    #return biases, weights\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(3, [784, 15, 10], Array{Float64,1}[[0.406031, 0.381599, 0.180761, 0.900402, 0.259479, 0.582121, 0.756559, 0.168323, 0.208358, 0.560963, 0.906883, 0.502223, 0.889426, 0.396306, 0.598851], [0.941026, 0.535058, 0.278317, 0.318891, 0.531942, 0.955771, 0.0228666, 0.0190559, 0.519874, 0.779196]], Array{Float64,2}[[0.867118 0.893728 … 0.169862 0.298852; 0.944274 0.766854 … 0.507048 0.869068; … ; 0.200642 0.00792705 … 0.432287 0.583057; 0.45196 0.718425 … 0.785632 0.857203], [0.75614 0.109277 … 0.34928 0.032948; 0.743618 0.792786 … 0.61498 0.562394; … ; 0.984853 0.221298 … 0.136003 0.653604; 0.884174 0.735888 … 0.157874 0.148666]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetwork([784,15,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sigmoid(z)\n",
    "  return 1.0 / (1.0 + exp(-z))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feedforward (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function feedforward(net,a)\n",
    "    for (b,w) in zip(net.biases, net.weights)\n",
    "        a = sigmoid.((w*a)+b)\n",
    "    end\n",
    "    return a\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function SGD(net, training_data, epochs, mini_batch_size, eta,test_data)\n",
    "    n_test = length(test_data)\n",
    "    n = length(training_data)\n",
    "    training_data2=collect(training_data)\n",
    "    mini_batches = [training_data2[k:k+(mini_batch_size-1)] for k=1:mini_batch_size:n-1]\n",
    "    for j in 1:epochs\n",
    "        for mini_batch in mini_batches\n",
    "            update_mini_batch(net, mini_batch, eta)\n",
    "        end\n",
    "       \n",
    "        print(\"epoch \",j, \": \",evaluate(net,test_data),\"  \")\n",
    "        \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "update_mini_batch (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function update_mini_batch(net, mini_batch, eta)\n",
    "    #def fn(a, y):\n",
    "     #   return np.sum(np.nan_to_num(-y*log(a)-(1-y)*log(1-a)))\n",
    "    nabla_b = [zeros(size(b)) for b in net.biases]\n",
    "    nabla_w = [zeros(size(w)) for w in net.weights]\n",
    "    for (x, y) in mini_batch\n",
    "        delta_nabla_b, delta_nabla_w = backprop(net,x, y)\n",
    "        nabla_b = [nb+dnb for (nb, dnb) in zip(nabla_b, delta_nabla_b)]\n",
    "        nabla_w = [nw+dnw for (nw, dnw) in zip(nabla_w, delta_nabla_w)]\n",
    "    end\n",
    "    net.weights = [w-(eta/size(mini_batch,1))*nw for (w, nw) in zip(net.weights, nabla_w)]\n",
    "    net.biases = [b-(eta/size(mini_batch,1))*nb for (b, nb) in zip(net.biases, nabla_b)]\n",
    "    \n",
    "    return net.weights,net.biases\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "backprop (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function backprop(net,x, y)\n",
    "    nabla_b = [zeros(size(b)) for b in net.biases]\n",
    "    nabla_w = [zeros(size(w)) for w in net.weights]\n",
    "    # feedforward\n",
    "    activation = x\n",
    "    activations = [x] # list to store all the activations, layer by layer\n",
    "    zs = [] # list to store all the z vectors, layer by layer\n",
    "    for (b, w) in zip(net.biases, net.weights)\n",
    "        #z = dot(w, activation)+b\n",
    "        z = (w*activation)+b\n",
    "        push!(zs,z)\n",
    "        activation = sigmoid.(z)\n",
    "        push!(activations,activation)\n",
    "    end\n",
    "    # backward pass\n",
    "    delta1 = Array(cost_derivative(net,activations[end], y) .* sigmoid_prime.(zs[end]))\n",
    "    delta=[]\n",
    "    for i in delta1\n",
    "        push!(delta,i)\n",
    "    end\n",
    "    nabla_b[end] = delta\n",
    "    nabla_w[end] = delta*transpose(activations[end-1])\n",
    "    # Note that the variable l in the loop below is used a little\n",
    "    # differently to the notation in Chapter 2 of the book.  Here,\n",
    "    # l = 1 means the last layer of neurons, l = 2 is the\n",
    "    # second-last layer, and so on.  It's a renumbering of the\n",
    "    # scheme in the book, used here to take advantage of the fact\n",
    "    # that Python can use negative indices in lists.\n",
    "    for l=net.numOfLayers-1:-1:2\n",
    "        z = zs[l-1]\n",
    "        #println(size(net.weights[l]), \" \", size(delta),\" \", size(sp))\n",
    "        delta = (transpose(net.weights[l])*delta) \n",
    "        nabla_b[l-1] = delta\n",
    "        nabla_w[l-1] = (delta * transpose(activations[l-1]))\n",
    "    end\n",
    "    return nabla_b, nabla_w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate(net,test_data)\n",
    "    test_results = [(findmax(feedforward(net,x))[2], findmax(y)[2]) for (x, y) in test_data]\n",
    "    #println(test_results)\n",
    "    return sum((x == y) for (x, y) in test_results) / size(test_data)[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cost_derivative (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cost_derivative(net,output_activations, y)\n",
    "    return output_activations-y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sigmoid_prime (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sigmoid_prime(z)\n",
    "     return sigmoid(z)*(1-sigmoid(z))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vectorized_result (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function vectorized_result(j)\n",
    "    e = zeros(10, 1)\n",
    "    e[j+1] = 1.0\n",
    "    return e\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Base.Iterators.Zip2{Array{Any,1},Array{Array{Float64,2},1}}(Any[[0.0, 0.0, 73.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 194.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 249.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 208.0, 0.0], [0.0, 9.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  41.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 16.0, 0.0], [0.0, 92.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  132.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 67.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  213.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  254.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  253.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 254.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 16.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 228.0, 0.0, 0.0, 0.0, 254.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 121.0, 54.0, 0.0, 0.0, 0.0, 0.0, 0.0]  …  [0.0, 0.0, 0.0, 0.0, 0.0, 229.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 6.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 25.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 229.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 80.0, 20.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 253.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 107.0, 0.0, 0.0], [0.0, 253.0, 40.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 191.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 254.0, 0.0, 0.0], [0.0, 253.0, 0.0, 0.0, 0.0, 225.0, 0.0, 0.0, 0.0, 9.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 47.0, 54.0, 0.0, 0.0], [0.0, 161.0, 0.0, 0.0, 0.0, 255.0, 0.0, 0.0, 0.0, 0.0  …  0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 39.0, 0.0, 0.0]], Array{Float64,2}[[0.0; 0.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 0.0; 0.0], [0.0; 1.0; … ; 0.0; 0.0], [1.0; 0.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 0.0; 0.0], [0.0; 1.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 0.0; 1.0], [0.0; 0.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 0.0; 1.0]  …  [0.0; 0.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 1.0; 0.0], [0.0; 0.0; … ; 0.0; 1.0], [1.0; 0.0; … ; 0.0; 0.0], [0.0; 1.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 0.0; 0.0], [0.0; 0.0; … ; 0.0; 0.0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_inp=reshape(trainX,(60000,784))\n",
    "training_inputs=[]\n",
    "for i=1:size(training_inp)[1]\n",
    "    push!(training_inputs,training_inp[i,:])\n",
    "end\n",
    "training_outputs = [vectorized_result(y) for y in trainY]\n",
    "training_data = zip(training_inputs, training_outputs)\n",
    "\n",
    "test_inp=reshape(testX,(10000,784))\n",
    "test_inputs=[]\n",
    "for i=1:size(test_inp)[1]\n",
    "    push!(test_inputs,test_inp[i,:])\n",
    "end\n",
    "test_outputs = [vectorized_result(y) for y in testY]\n",
    "test_data = zip(test_inputs, test_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: 0.1028  epoch 2: 0.1028  epoch 3: 0.1028  epoch 4: 0.1028  epoch 5: 0.1028  epoch 6: 0.1028  epoch 7: 0.1028  epoch 8: 0.1028  epoch 9: 0.1028  epoch 10: 0.1028  epoch 11: 0.1028  epoch 12: 0.1028  epoch 13: 0.1028  epoch 14: 0.1028  epoch 15: 0.1028  epoch 16: 0.1028  epoch 17: 0.1028  epoch 18: 0.1028  epoch 19: 0.1027  epoch 20: 0.1028  epoch 21: 0.1029  epoch 22: 0.103  epoch 23: 0.1031  epoch 24: 0.103  epoch 25: 0.103  epoch 26: 0.103  epoch 27: 0.1033  epoch 28: 0.1035  epoch 29: 0.1039  epoch 30: 0.1038  epoch 31: 0.1039  epoch 32: 0.1036  epoch 33: 0.1035  epoch 34: 0.1024  epoch 35: 0.1024  epoch 36: 0.102  "
     ]
    }
   ],
   "source": [
    "SGD(net,training_data, 100 , 30 , 3.0, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
